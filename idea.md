为什么图片在训练的时候能不能指定训练集的种类进行训练，如果使用imagenet预训练的结果呢？
现在使用的都是end to end模型


CNN提取出的特征图虽然很适合图像问题，但作为输入直接衔接到翻译问题中合适吗？ 
CNN的输出要怎么加入到RNN中才能更好的使图像中的注意力信息被文本化呢？ 
多次输入效果真的不如单次好吗，如果多次输入不同呢？ 
还有最原始的问题，RNN对长句子的遗忘问题怎么解决呢？

